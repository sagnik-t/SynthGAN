{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import mplcyberpunk as mplnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 12:16:04.442233: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-26 12:16:04.455444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 12:16:04.474964: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 12:16:04.475003: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-26 12:16:04.487754: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-26 12:16:08.020455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model, layers, optimizers, losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "from utils import DataLoader\n",
    "from models import DeepMF, GAN, VAE\n",
    "from models.metrics.elbo import ELBOLoss\n",
    "from models.layers import MinMaxNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = DataLoader.load_numpy(tag='movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder():\n",
    "    input_dim = 3\n",
    "    latent_dim = 10\n",
    "    \n",
    "    inputs = layers.Input(shape=(input_dim,), name='encode_input')\n",
    "    x = layers.Dense(units=10, name='dense1')(inputs)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2, name='leaky_relu_1')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8, name='batch_norm')(x)\n",
    "    outputs = layers.Dense(units=latent_dim, name='dense2')(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs, name='encoder')\n",
    "\n",
    "def build_decoder():\n",
    "    latent_dim = 10\n",
    "    output_dim = 3\n",
    "    \n",
    "    inputs = layers.Input(shape=(latent_dim,), name='decode_input')\n",
    "    x = layers.Dense(units=10, name='dense1')(inputs)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2, name='leaky_relu_1')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8, name='batch_norm')(x)\n",
    "    outputs = layers.Dense(units=output_dim, name='dense2')(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs, name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 12:16:10.132504: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 12:16:10.178246: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 12:16:10.178707: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 12:16:10.180598: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 12:16:10.180845: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 12:16:10.180983: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 12:16:10.302527: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 12:16:10.303027: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 12:16:10.303335: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 12:16:10.303590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2291 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721976372.296342    8441 service.cc:145] XLA service 0x78ef5400e940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721976372.296380    8441 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-07-26 12:16:12.361898: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-26 12:16:12.660228: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 102/2500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 184379.7969 - r2_score: -4.6153"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721976373.540336    8441 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 67576.3047 - r2_score: -0.9917 - learning_rate: 0.0100\n",
      "Epoch 2/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 2572.6602 - r2_score: 0.6364 - learning_rate: 0.0100\n",
      "Epoch 3/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 840us/step - loss: 2286.0134 - r2_score: 0.6324 - learning_rate: 0.0100\n",
      "Epoch 4/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 757us/step - loss: 2212.9658 - r2_score: 0.6317 - learning_rate: 0.0100\n",
      "Epoch 5/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 982us/step - loss: 2295.8164 - r2_score: 0.6289 - val_loss: 24.0898 - val_r2_score: 0.6606 - learning_rate: 0.0100\n",
      "Epoch 6/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2195.0364 - r2_score: 0.6325 - learning_rate: 0.0100\n",
      "Epoch 7/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 2231.4624 - r2_score: 0.6323 - learning_rate: 0.0100\n",
      "Epoch 8/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 913us/step - loss: 2172.6172 - r2_score: 0.6390 - learning_rate: 0.0100\n",
      "Epoch 9/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 783us/step - loss: 2306.9641 - r2_score: 0.6331 - learning_rate: 0.0100\n",
      "Epoch 10/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 964us/step - loss: 2203.4985 - r2_score: 0.6320 - val_loss: 362.8319 - val_r2_score: 0.6547 - learning_rate: 0.0100\n",
      "Epoch 11/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 767us/step - loss: 2255.9783 - r2_score: 0.6366 - learning_rate: 0.0100\n",
      "Epoch 12/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 828us/step - loss: 2160.3086 - r2_score: 0.6600 - learning_rate: 1.0000e-03\n",
      "Epoch 13/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 939us/step - loss: 2156.0823 - r2_score: 0.6597 - learning_rate: 1.0000e-03\n",
      "Epoch 14/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 828us/step - loss: 2194.4143 - r2_score: 0.6603 - learning_rate: 1.0000e-03\n",
      "Epoch 15/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2204.2549 - r2_score: 0.6584 - val_loss: 433.6083 - val_r2_score: 0.6864 - learning_rate: 1.0000e-03\n",
      "Epoch 16/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 779us/step - loss: 2130.6606 - r2_score: 0.6620 - learning_rate: 1.0000e-03\n",
      "Epoch 17/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 979us/step - loss: 2152.9292 - r2_score: 0.6601 - learning_rate: 1.0000e-03\n",
      "Epoch 18/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723us/step - loss: 2217.2029 - r2_score: 0.6598 - learning_rate: 1.0000e-03\n",
      "Epoch 19/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 811us/step - loss: 2227.0725 - r2_score: 0.6626 - learning_rate: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 863us/step - loss: 2145.9153 - r2_score: 0.6646 - val_loss: 535.5751 - val_r2_score: 0.6831 - learning_rate: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 871us/step - loss: 2098.1047 - r2_score: 0.6635 - learning_rate: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 790us/step - loss: 2244.8611 - r2_score: 0.6634 - learning_rate: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 739us/step - loss: 2219.6028 - r2_score: 0.6637 - learning_rate: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 802us/step - loss: 2136.4932 - r2_score: 0.6637 - learning_rate: 1.0000e-05\n",
      "Epoch 25/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2207.6953 - r2_score: 0.6638 - val_loss: 73.7986 - val_r2_score: 0.6938 - learning_rate: 1.0000e-05\n",
      "Epoch 26/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 697us/step - loss: 2124.2805 - r2_score: 0.6656 - learning_rate: 1.0000e-05\n",
      "Epoch 27/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 727us/step - loss: 2139.4097 - r2_score: 0.6640 - learning_rate: 1.0000e-05\n",
      "Epoch 28/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 706us/step - loss: 2283.1316 - r2_score: 0.6603 - learning_rate: 1.0000e-05\n",
      "Epoch 29/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 689us/step - loss: 2135.5110 - r2_score: 0.6638 - learning_rate: 1.0000e-05\n",
      "Epoch 30/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2187.9180 - r2_score: 0.6644 - val_loss: 215.3201 - val_r2_score: 0.6887 - learning_rate: 1.0000e-05\n",
      "Epoch 31/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 827us/step - loss: 2252.9954 - r2_score: 0.6632 - learning_rate: 1.0000e-05\n",
      "Epoch 32/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 841us/step - loss: 2164.9893 - r2_score: 0.6646 - learning_rate: 1.0000e-05\n",
      "Epoch 33/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 833us/step - loss: 2205.5552 - r2_score: 0.6642 - learning_rate: 1.0000e-06\n",
      "Epoch 34/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 2172.5825 - r2_score: 0.6647 - learning_rate: 1.0000e-06\n",
      "Epoch 35/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2174.8062 - r2_score: 0.6646 - val_loss: 56.5923 - val_r2_score: 0.6959 - learning_rate: 1.0000e-06\n",
      "Epoch 36/1000\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 932us/step - loss: 2297.0364 - r2_score: 0.6622 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78f015ae2310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(encoder=build_encoder(), decoder=build_decoder(), latent_dim=10)\n",
    "vae.compile(optimizer=optimizers.Adam(learning_rate=0.01), loss=ELBOLoss, metrics=[metrics.R2Score()])\n",
    "vae.fit(\n",
    "    x=x_train,\n",
    "    y=x_train,\n",
    "    batch_size=32,\n",
    "    epochs=1000,\n",
    "    validation_data=(x_test, x_test),\n",
    "    validation_freq=5,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='r2_score', patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5),\n",
    "    ],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507us/step\n"
     ]
    }
   ],
   "source": [
    "x_train_embedded = vae.predict(x=x_train, mode='encode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    noise_dim = 100\n",
    "    latent_dim = 5\n",
    "    \n",
    "    inputs = layers.Input(shape=(noise_dim,), name='gen_input')\n",
    "    x = layers.Dense(units=10, name='dense_1')(inputs)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2, name='leaky_relu_1')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8, name='batch_norm')(x)\n",
    "    x = layers.Dense(20, name='dense_2')(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2, name='leaky_relu_2')(x)\n",
    "    x = layers.Dropout(rate=0.2, name='dropout')(x)\n",
    "    outputs = layers.Dense(units=10, name='dense3')(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs, name='generator')\n",
    "\n",
    "def build_discriminator():\n",
    "    latent_dim = 5\n",
    "    \n",
    "    inputs = layers.Input(shape=(10,), name='disc_input')\n",
    "    x = layers.Dense(units=4, name='dense4')(inputs)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2, name='leaky_relu1')(x)\n",
    "    x = layers.Dense(units=1, name='dense5')(x)\n",
    "    x = layers.Activation('sigmoid', name='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=x, name='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - disc_loss: 1.1554 - gen_loss: 0.9199 - loss: 0.0000e+00\n",
      "Epoch 2/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - disc_loss: 1.3993 - gen_loss: 0.8884 - loss: 0.0000e+00\n",
      "Epoch 3/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - disc_loss: 1.4060 - gen_loss: 0.7548 - loss: 0.0000e+00\n",
      "Epoch 4/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - disc_loss: 1.4032 - gen_loss: 0.7387 - loss: 0.0000e+00\n",
      "Epoch 5/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - disc_loss: 1.3529 - gen_loss: 0.7759 - loss: 0.0000e+00\n",
      "Epoch 6/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - disc_loss: 1.3457 - gen_loss: 0.7646 - loss: 0.0000e+00\n",
      "Epoch 7/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - disc_loss: 1.3827 - gen_loss: 0.7663 - loss: 0.0000e+00\n",
      "Epoch 8/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - disc_loss: 1.3574 - gen_loss: 0.7367 - loss: 0.0000e+00\n",
      "Epoch 9/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - disc_loss: 1.3520 - gen_loss: 0.7566 - loss: 0.0000e+00\n",
      "Epoch 10/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3715 - gen_loss: 0.7714 - loss: 0.0000e+00\n",
      "Epoch 11/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 974us/step - disc_loss: 1.3511 - gen_loss: 0.7879 - loss: 0.0000e+00\n",
      "Epoch 12/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3844 - gen_loss: 0.7264 - loss: 0.0000e+00\n",
      "Epoch 13/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3630 - gen_loss: 0.7485 - loss: 0.0000e+00\n",
      "Epoch 14/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3856 - gen_loss: 0.7403 - loss: 0.0000e+00\n",
      "Epoch 15/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993us/step - disc_loss: 1.4024 - gen_loss: 0.7300 - loss: 0.0000e+00\n",
      "Epoch 16/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3922 - gen_loss: 0.7353 - loss: 0.0000e+00\n",
      "Epoch 17/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3645 - gen_loss: 0.7822 - loss: 0.0000e+00\n",
      "Epoch 18/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3670 - gen_loss: 0.7451 - loss: 0.0000e+00\n",
      "Epoch 19/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3960 - gen_loss: 0.7537 - loss: 0.0000e+00\n",
      "Epoch 20/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3758 - gen_loss: 0.7325 - loss: 0.0000e+00\n",
      "Epoch 21/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3708 - gen_loss: 0.7648 - loss: 0.0000e+00\n",
      "Epoch 22/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3798 - gen_loss: 0.7411 - loss: 0.0000e+00\n",
      "Epoch 23/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3938 - gen_loss: 0.7076 - loss: 0.0000e+00\n",
      "Epoch 24/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3893 - gen_loss: 0.7161 - loss: 0.0000e+00\n",
      "Epoch 25/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3806 - gen_loss: 0.7101 - loss: 0.0000e+00\n",
      "Epoch 26/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3726 - gen_loss: 0.7426 - loss: 0.0000e+00\n",
      "Epoch 27/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3765 - gen_loss: 0.7354 - loss: 0.0000e+00\n",
      "Epoch 28/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3745 - gen_loss: 0.7393 - loss: 0.0000e+00\n",
      "Epoch 29/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.4002 - gen_loss: 0.7292 - loss: 0.0000e+00\n",
      "Epoch 30/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3866 - gen_loss: 0.7154 - loss: 0.0000e+00\n",
      "Epoch 31/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3942 - gen_loss: 0.7175 - loss: 0.0000e+00\n",
      "Epoch 32/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3629 - gen_loss: 0.7736 - loss: 0.0000e+00\n",
      "Epoch 33/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3957 - gen_loss: 0.7201 - loss: 0.0000e+00\n",
      "Epoch 34/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3863 - gen_loss: 0.7155 - loss: 0.0000e+00\n",
      "Epoch 35/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3865 - gen_loss: 0.7143 - loss: 0.0000e+00\n",
      "Epoch 36/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3899 - gen_loss: 0.7658 - loss: 0.0000e+00\n",
      "Epoch 37/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.4047 - gen_loss: 0.7162 - loss: 0.0000e+00\n",
      "Epoch 38/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3783 - gen_loss: 0.7262 - loss: 0.0000e+00\n",
      "Epoch 39/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3892 - gen_loss: 0.7206 - loss: 0.0000e+00\n",
      "Epoch 40/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3973 - gen_loss: 0.7289 - loss: 0.0000e+00\n",
      "Epoch 41/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3835 - gen_loss: 0.7138 - loss: 0.0000e+00\n",
      "Epoch 42/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3782 - gen_loss: 0.7387 - loss: 0.0000e+00\n",
      "Epoch 43/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3863 - gen_loss: 0.7236 - loss: 0.0000e+00\n",
      "Epoch 44/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3918 - gen_loss: 0.7277 - loss: 0.0000e+00\n",
      "Epoch 45/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3914 - gen_loss: 0.7240 - loss: 0.0000e+00\n",
      "Epoch 46/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3841 - gen_loss: 0.7219 - loss: 0.0000e+00\n",
      "Epoch 47/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3969 - gen_loss: 0.7171 - loss: 0.0000e+00\n",
      "Epoch 48/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3866 - gen_loss: 0.7338 - loss: 0.0000e+00\n",
      "Epoch 49/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993us/step - disc_loss: 1.4030 - gen_loss: 0.7101 - loss: 0.0000e+00\n",
      "Epoch 50/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - disc_loss: 1.3847 - gen_loss: 0.7454 - loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(\n",
    "    generator=build_generator(),\n",
    "    discriminator=build_discriminator(),\n",
    "    noise_dim=100\n",
    ")\n",
    "\n",
    "gan.compile(\n",
    "    gen_optimizer=optimizers.Adam(),\n",
    "    disc_optimizer=optimizers.Adam()\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    x=x_train_embedded,\n",
    "    epochs=50,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "gan.save(filepath=Config.Paths.REGISTRY_PATH / 'gan.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = keras.models.load_model(Config.Paths.REGISTRY_PATH / 'gan.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "STD_DEV = 1.5\n",
    "noise = np.random.normal(0, STD_DEV, (50000, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data = gan.predict(noise).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step\n"
     ]
    }
   ],
   "source": [
    "gen_data_decoded = vae.predict(x=gen_data, mode='decode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(arr, min_val=0, max_val=1):\n",
    "    current_min = np.min(arr)\n",
    "    current_max = np.max(arr)\n",
    "    \n",
    "    normalized_arr = min_val + (arr - current_min) * (max_val - min_val) / (current_max - current_min)\n",
    "    \n",
    "    return normalized_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0  \n",
       "4.0    44401\n",
       "3.0     4988\n",
       "5.0      441\n",
       "2.0      164\n",
       "1.0        6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(normalize_array(gen_data_decoded[:, 2], 1, 5).round()).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
